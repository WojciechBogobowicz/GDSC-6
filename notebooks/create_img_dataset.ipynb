{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../src/\")\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Iterable\n",
    "import librosa\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchvision\n",
    "\n",
    "THRESHOLD_LENGTH = int(0.05 * 1e7)\n",
    "BATH_SIZE = 4\n",
    "RESIZE_SIZE = 256\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"]=\"max_split_size_mb:512\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/metadata.csv\")\n",
    "df[\"path\"] = df[\"path\"].apply(lambda x: \"../\" + x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dst_path\"] = df[\"path\"].apply(lambda x: x.replace(\"/data/\", \"/img_data/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.xticks(np.linspace(0, 3, 30)*1e7, rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (x - torch.min(x)) / (torch.max(x) - torch.min(x))\n",
    "\n",
    "\n",
    "class SpectrogramsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, paths, labels: str, threshold_len: int, transforms=None):\n",
    "        super().__init__()\n",
    "        self.paths = list(paths)\n",
    "        self.labels = torch.tensor(list(labels), dtype=torch.float32)\n",
    "        self.threshold_len = threshold_len\n",
    "        # TODO move transforms somewhere\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.path_to_spectrogram(self.paths[idx])\n",
    "        x = torch.tensor(x)\n",
    "        if self.transforms:\n",
    "            x = self.transforms(x)\n",
    "        return x, self.labels[idx]\n",
    "\n",
    "    def path_to_spectrogram(self, path: str) -> np.array:\n",
    "        waveform, _ = torchaudio.load(path)\n",
    "        if waveform.size(1) < self.threshold_len:\n",
    "            padding = int(self.threshold_len - waveform.size(1))\n",
    "            waveform = torch.cat((waveform, torch.zeros((1, padding))), dim=1)\n",
    "        elif waveform.size(1) > self.threshold_len:\n",
    "            waveform = waveform[:, : self.threshold_len]\n",
    "        return librosa.amplitude_to_db(\n",
    "            np.abs(librosa.stft(waveform.numpy())), ref=np.max\n",
    "        )\n",
    "\n",
    "\n",
    "transforms = torch.nn.Sequential(\n",
    "    torchvision.transforms.Resize((RESIZE_SIZE, RESIZE_SIZE)), Normalize()\n",
    ")\n",
    "\n",
    "train_df = df[df[\"subset\"] == \"train\"]\n",
    "val_df = df[df[\"subset\"] == \"validation\"]\n",
    "\n",
    "train_ds = SpectrogramsDataset(\n",
    "    train_df[\"path\"], train_df[\"label\"], THRESHOLD_LENGTH, transforms\n",
    ")\n",
    "val_ds = SpectrogramsDataset(\n",
    "    val_df[\"path\"], val_df[\"label\"], THRESHOLD_LENGTH, transforms\n",
    ")\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, shuffle=True, batch_size=BATH_SIZE)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, shuffle=True, batch_size=BATH_SIZE * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(\n",
    "                1, 16, kernel_size=7, stride=1, padding=3\n",
    "            ),  # 16, 1024, 1024\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),  # 16, 512, 512\n",
    "            torch.nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),  # 32, 512, 512\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),  # 32, 512, 512\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # 64, 256, 256\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),  # 64, 128, 128\n",
    "        )\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc = torch.nn.Linear(64 * int(RESIZE_SIZE / 8) ** 2, num_classes)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def count_correct(y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "    preds = torch.argmax(y_pred, dim=1)\n",
    "    return (preds == y_true).float().sum()\n",
    "\n",
    "\n",
    "def validate(\n",
    "    model: torch.nn.Module, loss_fn: torch.nn.CrossEntropyLoss, dataloader\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    all = 0\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        y_pred = model(X_batch.cuda())\n",
    "        all += len(y_pred)\n",
    "        loss += loss_fn(y_pred, y_batch.to(device)).sum()\n",
    "        correct += count_correct(y_pred, y_batch.to(device))\n",
    "        torch.cuda.empty_cache()\n",
    "    return loss / all, correct / all\n",
    "\n",
    "\n",
    "def fit(\n",
    "    model: torch.nn.Module,\n",
    "    optimiser: torch.optim.Optimizer,\n",
    "    loss_fn: torch.nn.CrossEntropyLoss,\n",
    "    train_dl,\n",
    "    val_dl,\n",
    "    epochs: int,\n",
    "    print_metrics: str = True,\n",
    "):\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for X_batch, y_batch in train_dl:\n",
    "            y_pred = model(X_batch.to(device))\n",
    "            loss = loss_fn(y_pred, y_batch.to(device))\n",
    "\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            optimiser.zero_grad()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        if print_metrics:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                train_loss, train_acc = validate(\n",
    "                    model=model, loss_fn=loss_fn, dataloader=train_dl\n",
    "                )\n",
    "                val_loss, val_acc = validate(\n",
    "                    model=model, loss_fn=loss_fn, dataloader=val_dl\n",
    "                )\n",
    "                print(\n",
    "                    f\"Epoch {epoch}: \"\n",
    "                    f\"train loss = {train_loss:.3f} (acc: {train_acc:.3f}), \"\n",
    "                    f\"validation loss = {val_loss:.3f} (acc: {val_acc:.3f})\"\n",
    "                )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_loss, train_acc = validate(\n",
    "            model=model, loss_fn=loss_fn, dataloader=train_dl\n",
    "        )\n",
    "        val_loss, val_acc = validate(model=model, loss_fn=loss_fn, dataloader=val_dl)\n",
    "        print(\n",
    "            \"Training ended: \"\n",
    "            f\"train loss = {train_loss:.3f} (acc: {train_acc:.3f}), \"\n",
    "            f\"validation loss = {val_loss:.3f} (acc: {val_acc:.3f})\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleClassifier(66).to(device)\n",
    "fit(\n",
    "    model=model,\n",
    "    optimiser=torch.optim.Adam(model.parameters()),\n",
    "    loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "    train_dl=train_dl,\n",
    "    val_dl=val_dl,\n",
    "    epochs=5,\n",
    "    print_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
